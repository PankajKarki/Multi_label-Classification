{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook makes use of Markov model for word prediction. Specifically 2nd order Markov model is deployed here for next word prediction. As an example of the Markov chain, an attempt is made to generate a new song lyrics from a bunch of Eminem song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the text file containing the training data\n",
    "training_data_file = 'eminem_songs_lyrics.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(sentence):\n",
    "    return sentence.translate(str.maketrans('','', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(dictionary, key, value):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = []\n",
    "    dictionary[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2probabilitydict(given_list):\n",
    "    probability_dict = {}\n",
    "    given_list_length = len(given_list)\n",
    "    for item in given_list:\n",
    "        probability_dict[item] = probability_dict.get(item, 0) + 1\n",
    "    for key, value in probability_dict.items():\n",
    "        probability_dict[key] = value / given_list_length\n",
    "    return probability_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_word = {}\n",
    "second_word = {}\n",
    "transitions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a Markov model based on the data in training_data_file\n",
    "def train_markov_model():\n",
    "    for line in open(training_data_file):\n",
    "        tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "        tokens_length = len(tokens)\n",
    "        for i in range(tokens_length):\n",
    "            token = tokens[i]\n",
    "            if i == 0:\n",
    "                initial_word[token] = initial_word.get(token, 0) + 1\n",
    "            else:\n",
    "                prev_token = tokens[i - 1]\n",
    "                if i == tokens_length - 1:\n",
    "                    add2dict(transitions, (prev_token, token), 'END')\n",
    "                if i == 1:\n",
    "                    add2dict(second_word, prev_token, token)\n",
    "                else:\n",
    "                    prev_prev_token = tokens[i - 2]\n",
    "                    add2dict(transitions, (prev_prev_token, prev_token), token)\n",
    "    \n",
    "    # Normalize the distributions\n",
    "    initial_word_total = sum(initial_word.values())\n",
    "    for key, value in initial_word.items():\n",
    "        initial_word[key] = value / initial_word_total\n",
    "        \n",
    "    for prev_word, next_word_list in second_word.items():\n",
    "        second_word[prev_word] = list2probabilitydict(next_word_list)\n",
    "        \n",
    "    for word_pair, next_word_list in transitions.items():\n",
    "        transitions[word_pair] = list2probabilitydict(next_word_list)\n",
    "    \n",
    "    print('Training successful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training successful.\n"
     ]
    }
   ],
   "source": [
    "train_markov_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(dictionary):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for key, value in dictionary.items():\n",
    "        cumulative += value\n",
    "        if p0 < cumulative:\n",
    "            return key\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sentences = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sample text\n",
    "def generate():\n",
    "    for i in range(number_of_sentences):\n",
    "        sentence = []\n",
    "        # Initial word\n",
    "        word0 = sample_word(initial_word)\n",
    "        sentence.append(word0)\n",
    "        # Second word\n",
    "        word1 = sample_word(second_word[word0])\n",
    "        sentence.append(word1)\n",
    "        # Subsequent words untill END\n",
    "        while True:\n",
    "            word2 = sample_word(transitions[(word0, word1)])\n",
    "            if word2 == 'END':\n",
    "                break\n",
    "            sentence.append(word2)\n",
    "            word0 = word1\n",
    "            word1 = word2\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gumusunu gumusunu guppucchuku\n",
      "toli pongullo daagina taapam taapam sayyaata laadindi naalo\n",
      "engine nee alli chinduduve\n",
      "assalem taragodhe\n",
      "naa cable lallo jeevam nuvvene\n",
      "yanthara lokapu sundari ve\n",
      "naa priyamo priyamo battery ve\n",
      "entamai marapo inni oohallo tellaare reyalle\n",
      "nee namaajullo onamaalu marichaa\n",
      "nee peru naa peru telusaa mari hrudayaala kadha maare neelo\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
