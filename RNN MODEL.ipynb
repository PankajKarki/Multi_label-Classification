{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport pickle\nimport os, re\nprint(os.listdir(\"../input\"))\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['testData.tsv', 'sampleSubmission.csv', 'labeledTrainData.tsv', 'unlabeledTrainData.tsv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "053dcdb1ed3f2256398eb114fc246fcc34aaa8cf"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/labeledTrainData.tsv\", header = 0, delimiter = '\\t')\ntest = pd.read_csv(\"../input/testData.tsv\", header = 0, delimiter = '\\t')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d7f2d3250b2e4c13182065cf1162e82750b6401"
      },
      "cell_type": "code",
      "source": "test[\"sentiment\"] = test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\ny_test = test[\"sentiment\"]",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "1. Define some pre-processing functions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31de028b5dd4ff71f59e5ed9552e826db5730d18",
        "_kg_hide-input": false
      },
      "cell_type": "code",
      "source": "def html_to_text(review):\n    \"\"\"Return extracted text string from provided HTML string.\"\"\"\n    review_text = BeautifulSoup(review, \"lxml\").get_text()\n    if len(review_text) == 0:\n        review_text = review\n    review_text = re.sub(r\"\\<.*\\>\", \"\", review_text)\n    try:\n        review_text = review_text.encode('ascii', 'ignore').decode('ascii')#ignore \\xc3 etc.\n    except UnicodeDecodeError:\n        review_text = review_text.decode(\"ascii\", \"ignore\")\n    return review_text\n\n\ndef letters_only(text):\n    \"\"\"Return input string with only letters (no punctuation, no numbers).\"\"\"\n    # It is probably worth experimenting with milder prepreocessing (eg just removing punctuation)\n    return re.sub(\"[^a-zA-Z]\", \" \", text)\n\ndef rnn_tokenizer_review_preprocess(review):\n    \"\"\"Preprocessing used before fitting/transforming RNN tokenizer - Html->text, remove punctuation/#s, lowercase.\"\"\"\n    return letters_only(html_to_text(review)).lower()",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08b563cc57a7d167b8d3d339766b3e2fa2b2a9bc",
        "_kg_hide-input": false
      },
      "cell_type": "code",
      "source": "def get_train_val_data(reviews_to_features_fn=None, df = train):\n    #df = pd.read_csv('labeledTrainData.tsv', header=0, quotechar='\"', sep='\\t')\n    SEED = 1000\n    # Shuffle data frame rows\n    np.random.seed(SEED)\n    df = df.iloc[np.random.permutation(len(df))]\n\n    if reviews_to_features_fn:\n        feature_rows = df[\"review\"].map(reviews_to_features_fn)\n        if type(feature_rows[0]) == np.ndarray:\n            num_instances = len(feature_rows)\n            num_features = len(feature_rows[0])\n            x = np.concatenate(feature_rows.values).reshape((num_instances, num_features))\n        else:\n            x = feature_rows\n    else:\n        x = df[\"review\"]\n\n    y = df[\"sentiment\"]\n\n    # Split 80/20\n    test_start_index = int(df.shape[0] * .8)\n    x_train = x[0:test_start_index]\n    y_train = y[0:test_start_index]\n    x_val = x[test_start_index:]\n    y_val = y[test_start_index:]\n\n    return x_train, y_train, x_val, y_val",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b8a570f1bd8ce43d430223bf0c2ea198f63987e"
      },
      "cell_type": "markdown",
      "source": "## Propcessed the data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5157a1e02bebed4beba493b320fbe55b86b6d0d"
      },
      "cell_type": "code",
      "source": "x_train, y_train, x_val, y_val = get_train_val_data(rnn_tokenizer_review_preprocess)\nx_test = test[\"review\"].map(rnn_tokenizer_review_preprocess)\ny_test = test[\"sentiment\"]",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a25e020f8ef1f4fa2331797db431f03190f4cd94"
      },
      "cell_type": "markdown",
      "source": "## Generate the text sequence for RNN model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f297e492c8ee5ad668a10a44752b2a8a7662ed5"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "536dd9544c9c7a65648ff798cf954ee93c799c3b"
      },
      "cell_type": "code",
      "source": "np.random.seed(1000)\nnum_most_freq_words_to_include = 5000\nMAX_REVIEW_LENGTH_FOR_KERAS_RNN = 500\nembedding_vector_length = 32",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "958394bdd673d0a6436b312a6ae2608a74392be5"
      },
      "cell_type": "code",
      "source": "train_review_list = x_train.tolist()\nval_review_list = x_val.tolist()\ntest_review_list = x_test.tolist()\nall_review_list = x_train.tolist() + x_val.tolist()",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bad7335af88ddfc4860759be06fa33b4489163ac"
      },
      "cell_type": "code",
      "source": "tokenizer = Tokenizer(num_words=num_most_freq_words_to_include)\ntokenizer.fit_on_texts(all_review_list)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1b344baa63948e98603c8ab1a521267847afa767",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_reviews_tokenized = tokenizer.texts_to_sequences(train_review_list)\nx_train = pad_sequences(train_reviews_tokenized, maxlen=MAX_REVIEW_LENGTH_FOR_KERAS_RNN)\nval_review_tokenized = tokenizer.texts_to_sequences(val_review_list)\nx_val = pad_sequences(val_review_tokenized, maxlen=MAX_REVIEW_LENGTH_FOR_KERAS_RNN)\ntest_review_tokenized = tokenizer.texts_to_sequences(test_review_list)\nx_test = pad_sequences(test_review_tokenized, maxlen=MAX_REVIEW_LENGTH_FOR_KERAS_RNN)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a46c9ed6f109dd2ddcd0ef3dbf950919ae836a5"
      },
      "cell_type": "markdown",
      "source": "## Architecture the RNN Model\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bde593b0733640e3a94c5763be24c5953b41a87a"
      },
      "cell_type": "code",
      "source": "from keras.layers import Input, Embedding, Dropout, Conv1D, MaxPool1D, GRU, LSTM, Dense\nfrom keras.models import Model",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ee5933ffcb3bffe6b9dcd291a9584176b9b7cfa"
      },
      "cell_type": "code",
      "source": "def rnn_model(use_cnn = True, use_lstm = False):\n    input_sequences = Input(shape = (MAX_REVIEW_LENGTH_FOR_KERAS_RNN,))\n    initial_dropout = 0.2\n    embedding_layer = Embedding(input_dim = num_most_freq_words_to_include, \n                                output_dim = embedding_vector_length,\n                                input_length = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)\n    X = embedding_layer(input_sequences)\n    X = Dropout(0.2)(X)\n    if use_cnn:\n        X = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(X)\n        X = MaxPool1D(pool_size=2)(X)\n        \n    # Add GRU layers\n    dropout_W = 0.0\n    dropout_U = 0.0\n    \n    if use_lstm:\n        X = LSTM(100, dropout = dropout_W, recurrent_dropout = dropout_U)(X)\n    else:\n        X = GRU(100, dropout=dropout_W, recurrent_dropout=dropout_U)(X)\n    X = Dropout(0.2)(X)\n    outputs= Dense(1, activation='sigmoid')(X)\n    model = Model(inputs = input_sequences, outputs = outputs)\n    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return model",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f311cc8bd5b90757075c20063cc2a3e3aa527abf"
      },
      "cell_type": "markdown",
      "source": "## GRU Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7ab8324306bca315aaa53e04bd8f2590af7d16d"
      },
      "cell_type": "code",
      "source": "gru_model = rnn_model(use_lstm=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "146ac0f707f73121ed21d78492e9bea9d4f6daa6"
      },
      "cell_type": "code",
      "source": "gru_model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6578a457e309241a4e46b7548ee6df0ceb8bb55e"
      },
      "cell_type": "code",
      "source": "gru_model.fit(x_train, y_train, batch_size=64, epochs=3, validation_data=[x_val, y_val])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90f26217c71dd73a12c0af3b30ccf30461553e93"
      },
      "cell_type": "code",
      "source": "y_test_pred_gru = gru_model.predict(x_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e45e0656e7028fb47b29508ce01f7c0e18c07ef"
      },
      "cell_type": "code",
      "source": "print(\"Accuracy on test set using lstm: %0.3f%%\"%(accuracy_score(y_test, y_test_pred_gru.round())*100))\nprint(\"Precision on test set using lstm: %0.3f\"%(precision_score(y_test, y_test_pred_gru.round())))\nprint(\"Recall on test setusing lstm: %0.3f\"%(recall_score(y_test, y_test_pred_gru.round())))\nprint(\"F1-Score on test set using lstm: %0.3f\"%(f1_score(y_test, y_test_pred_gru.round())))\nprint(\"F1-Score on test set using lstm: %0.3f\"%(f1_score(y_test, y_test_pred_gru.round()))",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unexpected EOF while parsing (<ipython-input-30-1236e7bff10e>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-1236e7bff10e>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    print(\"F1-Score on test set using lstm: %0.3f\"%(f1_score(y_test, y_test_pred_lstm.round()))\u001b[0m\n\u001b[0m                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "cc6234580406c761bdf9c4ffb7a4fe8addb07c53"
      },
      "cell_type": "markdown",
      "source": "## LSTM Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0c1e33a37728207ce8a43d132cfb77c00387529"
      },
      "cell_type": "code",
      "source": "lstm_model = rnn_model(use_lstm=True)\nlstm_model.summary()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 500)               0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 500, 32)           160000    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 500, 32)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 500, 32)           3104      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 100)               53200     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 101       \n=================================================================\nTotal params: 216,405\nTrainable params: 216,405\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe8ed887418e7769f36aa88c036393e6043d2882"
      },
      "cell_type": "code",
      "source": "lstm_model.fit(x_train, y_train, batch_size = 64, epochs = 3, validation_data=[x_val, y_val])",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 20000 samples, validate on 5000 samples\nEpoch 1/3\n20000/20000 [==============================] - 181s 9ms/step - loss: 0.4813 - acc: 0.7428 - val_loss: 0.3607 - val_acc: 0.8398\nEpoch 2/3\n20000/20000 [==============================] - 176s 9ms/step - loss: 0.2717 - acc: 0.8926 - val_loss: 0.2807 - val_acc: 0.8852\nEpoch 3/3\n20000/20000 [==============================] - 175s 9ms/step - loss: 0.2208 - acc: 0.9173 - val_loss: 0.2991 - val_acc: 0.8908\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7f51239504a8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f5f2da506eefc143b721536a0f336497da6779c0"
      },
      "cell_type": "code",
      "source": "y_test_pred_lstm = lstm_model.predict(x_test)",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1c073746af3da66c91b85f275540b949011ab099"
      },
      "cell_type": "markdown",
      "source": "### Evaluate the Model Performance on Test Data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "76fae589c7c73520ed7b2eeda37d730e1c5160e5"
      },
      "cell_type": "code",
      "source": "print(\"Accuracy on test set using lstm: %0.3f%%\"%(accuracy_score(y_test, y_test_pred_lstm.round())*100))\nprint(\"Precision on test set using lstm: %0.3f\"%(precision_score(y_test, y_test_pred_lstm.round())))\nprint(\"Recall on test setusing lstm: %0.3f\"%(recall_score(y_test, y_test_pred_lstm.round())))\nprint(\"F1-Score on test set using lstm: %0.3f\"%(f1_score(y_test, y_test_pred_lstm.round())))\nprint(\"F1-Score on test set using lstm: %0.3f\"%(f1_score(y_test, y_test_pred_lstm.round()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "18b827d13a008791947e1583c6a75d144c4cb306"
      },
      "cell_type": "markdown",
      "source": "Overall, GRU model performs slightly well than LSTM, but the difference is very small."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}